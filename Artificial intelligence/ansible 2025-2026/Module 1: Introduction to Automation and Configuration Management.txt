

*****************************************************************************************
*****************************************************************************************
*****************************************************************************************



Module 1: Introduction to Automation and Configuration Management


Key Topics
      Concept of IT Automation
      What is Configuration Management
      Benefits of automation tools (Ansible, Puppet, Chef, SaltStack)
      Why choose Ansible (agentless, YAML, SSH-based)
      Overview of DevOps and Infrastructure as Code (IaC)
      Comparison: Manual vs Automated provisioning


Learning Outcomes
    Understand automation fundamentals
    Explain Ansible‚Äôs role in DevOps lifecycle







üß™ Module 1 ‚Äì Lab Topics: Introduction to Automation and Configuration Management

| **Lab No.** | **Lab Title / Focus Area**                                                                           |
| ----------- | ---------------------------------------------------------------------------------------------------- |
| **Lab 1**   | Exploring Traditional vs. Automated Configuration ‚Äî Manual Setup vs. Scripted Setup                  |
| **Lab 2**   | Understanding Automation Tools: Comparing Ansible, Puppet, Chef, and SaltStack (Feature Exploration) |
| **Lab 3**   | Installing and Verifying Ansible on a Control Node                                                   |
| **Lab 4**   | Setting Up Managed Nodes and SSH Key-Based Authentication                                            |
| **Lab 5**   | First Ansible Command ‚Äî Using the `ping` Module to Verify Connectivity                               |
| **Lab 6**   | Creating and Managing an Ansible Inventory File (Static Hosts)                                       |
| **Lab 7**   | Running Simple Ad-hoc Commands for Package and Service Management                                    |
| **Lab 8**   | Editing and Understanding YAML Syntax for Automation Tasks                                           |
| **Lab 9**   | Configuring and Viewing the `ansible.cfg` File (Defaults and Overrides)                              |
| **Lab 10**  | Exploring Ansible Facts ‚Äî Gathering System Information from Remote Nodes                             |
| **Lab 11**  | Writing a Basic Ansible Playbook for System Update and Verification                                  |
| **Lab 12**  | Demonstrating Agentless Automation: Running Tasks via SSH Without Agents                             |
| **Lab 13**  | Comparing Manual Server Configuration vs. Automated Ansible Playbook Execution                       |
| **Lab 14**  | Introduction to Infrastructure as Code (IaC) ‚Äî Concept Demo Using Simple Ansible Scripts             |
| **Lab 15**  | Integrating Ansible with DevOps Workflow ‚Äî Automating a Sample Deployment Pipeline Overview          |




*****************************************************************************************
*****************************************************************************************
*****************************************************************************************




















===================================================================================
üß™ Lab 1 ‚Äì Exploring Traditional vs. Automated Configuration

Topic: Manual Setup vs. Scripted (Automated) Setup
===================================================================================


üß† 1. Concept Overview
System Configuration refers to the process of setting up servers, installing software, 
and ensuring services are running correctly.



There are two major approaches to doing this:
      Traditional (Manual) Configuration
                  Admins perform setup tasks manually using terminal commands 
                  or GUIs on each system individually.
      
      Automated Configuration
                  Configuration tasks are written as scripts or playbooks and 
                  executed automatically across multiple systems using tools 
                  like Ansible, Puppet, or Chef.





‚öôÔ∏è 2. Traditional (Manual) Configuration
üîπ Characteristics
            Admin connects to each machine using SSH.
            Runs commands one by one.
            Configurations vary if any step is missed.
            Time-consuming for large environments.

üßæ Example ‚Äî Manual Apache Installation
      
      Let‚Äôs say an admin wants to install and start Apache HTTP Server on 3 servers.

                        # Run on every server manually
                        sudo apt update -y
                        sudo apt install apache2 -y
                        sudo systemctl enable apache2
                        sudo systemctl start apache2
                        sudo systemctl status apache2
      
      
                  ‚ö†Ô∏è Drawbacks
                  Must repeat on each node individually.
                  Prone to human error (typos, missed commands).
                  Difficult to maintain consistent configuration.
                  No audit trail or change versioning.







ü§ñ 3. Automated Configuration

Automation means using a tool or script to apply configurations 
consistently and repeatedly across all systems.

Tools like Ansible allow central management using YAML-based Playbooks.

üîπ How It Works (Ansible Example)
            Admin defines tasks in a YAML file (Playbook).
            Ansible connects via SSH to all target hosts (no agents needed).
            Executes the same configuration steps automatically.


üßæ Example ‚Äî Automated Apache Installation Using Ansible
      File: install_apache.yml

                  - name: Install and Start Apache Web Server
                    hosts: webservers
                    become: yes
                    tasks:
                      - name: Install Apache package
                        apt:
                          name: apache2
                          state: present
                  
                      - name: Ensure Apache is running
                        service:
                          name: apache2
                          state: started
                          enabled: yes
                  


            Run it with:
                  ansible-playbook -i inventory install_apache.yml



            ‚úÖ Advantages
                        One command manages all servers.
                        Idempotent: if Apache is already installed, it won‚Äôt reinstall.
                        Logs and reports are stored centrally.
                        Scalable: works on 10 or 10,000 servers identically.
                        




‚öñÔ∏è 4. Comparison: Manual vs. Automated Configuration

      | **Aspect**           | **Manual (Traditional)**   | **Automated (Using Ansible)**    |
      | -------------------- | -------------------------- | -------------------------------- |
      | **Execution Method** | Commands run manually      | Playbook runs via Ansible        |
      | **Consistency**      | May vary per admin or host | Guaranteed identical setup       |
      | **Scalability**      | Limited to few servers     | Manages hundreds easily          |
      | **Error Handling**   | Manual checking            | Automated logs & error reports   |
      | **Reusability**      | Repeated typing            | Reusable playbooks               |
      | **Change Tracking**  | None                       | Version-controlled (Git)         |
      | **Security**         | Depends on user discipline | Controlled via Vaults & Policies |



üß© 5. Real-Life Analogy

      Manual configuration = Cooking every dish from scratch each time.
      
      Automated configuration = Having a recipe (playbook) and a chef (Ansible) who
                                prepares identical dishes consistently every time.




‚úÖ Example Summary Output (When Using Ansible)

            PLAY [Install and Start Apache Web Server] ************************************
            
            TASK [Install Apache package] *************************************************
            changed: [192.168.10.120]
            changed: [192.168.10.121]
            
            TASK [Ensure Apache is running] ***********************************************
            ok: [192.168.10.120]
            ok: [192.168.10.121]
            
            PLAY RECAP ********************************************************************
            192.168.10.120      : ok=2 changed=1
            192.168.10.121      : ok=2 changed=1


      ‚úÖ Both servers are configured automatically ‚Äî consistent, fast, and logged.
















===================================================================================
üß© Lab 2 ‚Äì Understanding Automation Tools: Comparing Ansible, Puppet, Chef, and SaltStack

(Feature Exploration and Conceptual Understanding)
===================================================================================




            Ansible‚Äôs agentless, YAML-driven, push-based design makes it ideal for 
            today‚Äôs cloud, DevOps, and hybrid infrastructures, offering rapid 
            automation without the overhead of maintaining agents or mastering complex DSLs.





üéØ Objective

            To understand the key automation and configuration management tools used in
            modern IT environments, explore their architectural differences, and analyze
            why Ansible has become one of the most popular choices.
            


üß† 1. Concept Overview

      üîπ What is Configuration Management?
            Configuration management (CM) ensures systems maintain a 
            desired state ‚Äî specific versions of software, packages, and
            services ‚Äî across multiple machines.
      
            Instead of configuring servers manually, CM tools automate this
            process, ensuring consistency and reducing human error.



üß∞ 2. Major Automation Tools

      The four most widely used tools in the DevOps ecosystem are:

            Ansible ‚Äì Agentless, simple, and YAML-based.
            
            Puppet ‚Äì Mature enterprise tool using its own declarative DSL (Ruby-like).
            
            Chef ‚Äì Ruby-based, developer-oriented configuration management system.
            
            SaltStack ‚Äì Event-driven automation using Python and YAML (now part of VMware).



‚öôÔ∏è 3. Architecture Comparison

| **Feature / Aspect**  | **Ansible**                              | **Puppet**                      | **Chef**                         | **SaltStack**                     |
| --------------------- | ---------------------------------------- | ------------------------------- | -------------------------------- | --------------------------------- |
| **Language / Syntax** | YAML (Playbooks)                         | Puppet DSL (Ruby-style)         | Ruby                             | YAML (SLS files)                  |
| **Architecture Type** | **Agentless** (uses SSH)                 | Master‚ÄìAgent                    | Server‚ÄìClient                    | Master‚ÄìMinion (or agentless mode) |
| **Execution Model**   | Push-based (control node triggers tasks) | Pull-based (agent polls master) | Pull-based                       | Push / Pull both                  |
| **Ease of Setup**     | ‚≠ê Very easy                             | Moderate                        | Complex                          | Moderate                          |
| **Learning Curve**    | Low                                      | Medium                          | High                             | Medium                            |
| **Platform Support**  | Linux, Windows, macOS                    | Linux, Windows                  | Linux, Windows                   | Linux, Windows                    |
| **Community Support** | Very Large & Active                      | Mature & Stable                 | Strong DevOps Community          | Moderate (enterprise focus)       |
| **Best Use Case**     | Fast deployment, multi-cloud automation  | Policy-driven infra enforcement | Complex pipelines and compliance | Real-time event-driven ops        |
| **Agent Requirement** | ‚ùå None (agentless SSH)                   | ‚úÖ Yes                           | ‚úÖ Yes                            | Optional (Minion or SSH)          |
| **Primary Strength**  | Simplicity & Speed                       | Enterprise compliance           | Flexibility & integration        | Real-time communication           |








üß© 4. Workflow Example
            üü© Ansible (Agentless Automation)
            
                        - name: Install Apache using Ansible
                          hosts: webservers
                          become: yes
                          tasks:
                            - name: Ensure Apache is installed
                              apt:
                                name: apache2
                                state: present


            ‚û°Ô∏è Run via ansible-playbook -i inventory apache.yml
            
            Communication: Over SSH ‚Äî no agent required.
      







            üü® Puppet (Master‚ÄìAgent Model)
            
            You define a manifest in Ruby-style DSL:
            
            
                        package { 'httpd':
                          ensure => installed,
                        }
                        service { 'httpd':
                          ensure => running,
                        }




            ‚û°Ô∏è The Puppet Agent periodically contacts the Puppet
                Master for configuration updates










            üü• Chef (Client‚ÄìServer Model)
                        
                        Recipes written in Ruby, grouped in cookbooks:
                        
                        
                                    package 'httpd' do
                                      action :install
                                    end
                                    
                                    service 'httpd' do
                                      action [:enable, :start]
                                    end
                        
                        
            Chef Client pulls instructions from the Chef Server.







            üü¶ SaltStack (Event-Driven Automation)
            
                              Uses States (SLS files) written in YAML:
                              
                                                
                                                apache:
                                                  pkg.installed
                                                  service.running:
                                                    - enable: true
                              
            Can operate push (via Salt master) or pull (via minions).
            















üß© 5. Practical Use Comparison


| **Scenario**                                           | **Preferred Tool** | **Reason**                                 |
| ------------------------------------------------------ | ------------------ | ------------------------------------------ |
| Quick multi-server deployment                          | **Ansible**        | Agentless, simple playbooks                |
| Large regulated enterprise with compliance policies    | **Puppet**         | Centralized master with policy enforcement |
| DevOps pipeline with heavy Ruby integration            | **Chef**           | Deep Ruby customization                    |
| Real-time event-driven automation (SD-WAN, networking) | **SaltStack**      | Event bus and fast execution               |








‚ö° 6. Key Differences at a Glance

| Category | Agentless | Language Simplicity | Speed (Initial Use) | Cloud Integration |
|---------------|----------------|--------------------------|--------------------------|
| Ansible | ‚úÖ Yes | ‚≠ê YAML (Easy) | ‚≠ê‚≠ê‚≠ê‚≠ê | AWS, Azure, GCP Modules |
| Puppet | ‚ùå No | Medium | ‚≠ê‚≠ê‚≠ê | AWS, VMware Plugins |
| Chef | ‚ùå No | Complex (Ruby) | ‚≠ê‚≠ê | AWS SDK Integration |
| SaltStack | Optional | Medium (YAML) | ‚≠ê‚≠ê‚≠ê‚≠ê | Good via event system |










üîê 7. Why Ansible Stands Out
            
            ‚úÖ Agentless ‚Äî simpler, fewer security issues.
            ‚úÖ Human-readable YAML ‚Äî no programming background required.
            ‚úÖ Push-based execution ‚Äî instant configuration updates.
            ‚úÖ Modular ecosystem ‚Äî thousands of ready-to-use modules.
            ‚úÖ Strong community support ‚Äî Red Hat backed, widely adopted.
            



üß† 8. Key Takeaways

            All CM tools aim to enforce consistency and automation.
            Puppet and Chef are older, agent-based, and suited for large legacy systems.
            Ansible provides simplicity, agentless operation, and faster adoption.
            SaltStack adds flexibility for event-driven, near real-time automation.
            Choosing a tool depends on team skill set, environment size, and governance needs.
            
            











===================================================================================
EXTRA - Proxmox setup
===================================================================================

üß± 1. Understanding Proxmox CTs

                  When you create a CT (Container) in Proxmox using templates like
                  
                                    centos-9-stream-default_2025-xx-xx.txz,
                                    
                                    ubuntu-22.04-default_2025-xx-xx.tzst,
                  
                  
                  
                  you are creating LXC containers ‚Äî lightweight, isolated Linux 
                  environments that share the Proxmox host kernel.
                  
                  
                  
                  ‚û°Ô∏è These CTs behave like full Linux servers (with shell access, 
                  networking, and package managers) ‚Äî perfect for Ansible testing.
                  
                  They use fewer resources than full VMs and support SSH, Python, and 
                  systemd ‚Äî exactly what Ansible needs.



‚öôÔ∏è 2. Feasibility for Your Lab Simulation

      Yes ‚úÖ ‚Äî this setup is ideal for your Ansible lab:


| **Role**                  | **Container Name** | **Template / OS**                       | **Example IP** | **Purpose**  |
| ------------------------- | ------------------ | --------------------------------------- | -------------- | ------------ |
| **Master / Control Node** | `centos1`          | CentOS Stream 9 (`centos-9-stream.txz`) | 192.168.10.100 | Runs Ansible |
| **Node 2**                | `centos2`          | CentOS Stream 9 (`centos-9-stream.txz`) | 192.168.10.110 | Managed node |
| **Node 3**                | `ubuntu1`          | Ubuntu 22.04 (`ubuntu-22.04.tzst`)      | 192.168.10.120 | Managed node |






‚úÖ This architecture is perfectly valid ‚Äî Ansible is cross-platform
and can manage mixed environments.






üß™ 3. Compatibility Verification


| **Requirement**  | **CT Support**                                                    | **Status** |
| ---------------- | ----------------------------------------------------------------- | ---------- |
| Linux OS         | ‚úîÔ∏è Supported (CentOS, Ubuntu, Fedora)                             |            |
| Python installed | ‚úîÔ∏è Required on managed nodes                                      |            |
| SSH access       | ‚úîÔ∏è Works normally in CTs                                          |            |
| Systemd          | ‚úîÔ∏è Works in most LXC templates (except minimal images)            |            |
| Networking       | ‚úîÔ∏è CTs can use `vmbr0` or NAT bridge ‚Äî same subnet for simplicity |            |


            üü° Note: If SSH or Python isn‚Äôt installed by default in
                the CT template, you‚Äôll just install them once manually:


                                    # For CentOS
                                    dnf install -y python3 openssh-server
                                    systemctl enable --now sshd
                                    
                                    # For Ubuntu
                                    apt update -y
                                    apt install -y python3 openssh-server
                                    systemctl enable --now ssh
                                    








‚öôÔ∏è Ansible Lab Hardware Requirements (Proxmox Container Setup)


| **Node Name** | **OS Template**          | **IP Address** | **vCPU** | **RAM** | **Role**       |
| ------------- | ------------------------ | -------------- | -------- | ------- | -------------- |
| `centos1`     | CentOS Stream 9 (`.txz`) | 192.168.10.100 | 4        | 4 GB    | Ansible Master |
| `centos2`     | CentOS Stream 9 (`.txz`) | 192.168.10.110 | 2        | 2 GB    | Managed Node 1 |
| `ubuntu1`     | Ubuntu 22.04 (`.tzst`)   | 192.168.10.120 | 2        | 2 GB    | Managed Node 2 |






üß† 2. Key System Prerequisites

| **Component**           | **Requirement**                                                                         |
| ----------------------- | --------------------------------------------------------------------------------------- |
| **Python 3**            | Must be installed on all managed nodes (Ansible relies on Python for module execution). |
| **SSH Service**         | Required for master ‚Üî slave communication (`openssh-server` must be running).           |
| **Network**             | All nodes must be on **the same network bridge** (e.g., `vmbr0`) and reachable by IP.   |
| **Hostname Resolution** | Optionally configure `/etc/hosts` or local DNS for easier management.                   |
| **Root Access**         | Simplifies lab setup (can later switch to sudo users).                                  |



MAIN LAB
------------------------------------------

| **Node**              | **Hostname**     | **IP Address** | **Role / Purpose**                             |
| --------------------- | ---------------- | -------------- | ---------------------------------------------- |
| üè∞ **ansible-master** | `ansible-master` | `192.168.5.80` | Control Node (where Ansible will be installed) |
| üíª **centos-node1**   | `centos-node1`   | `192.168.5.81` | Managed Node 1 (CentOS target)                 |
| üíª **ubuntu-node2**   | `ubuntu-node2`   | `192.168.5.83` | Managed Node 2 (Ubuntu target)                 |














===================================================================================
üß™ Lab 3 ‚Äî Installing and Verifying Ansible on a Control Node
===================================================================================


üéØ Objective

      Install Ansible on the control node (ansible-master) and verify 
      it‚Äôs properly configured to manage other nodes.
      




üß± Lab Setup

| **Host**         | **Role**     | **IP Address** | **OS**          |
| ---------------- | ------------ | -------------- | --------------- |
| `ansible-master` | Control Node | 192.168.5.80   | CentOS Stream 9 |




‚öôÔ∏è Step-by-Step Procedure
Step 1: Update System Packages

      [root@ansible-master ~]# dnf update -y
      
      This ensures your package metadata and security updates are current.




Step 2: Enable EPEL Repository (Extra Packages for Enterprise Linux)

      [root@ansible-master ~]# dnf install epel-release -y
      
      EPEL provides additional open-source packages like Ansible.



Step 3: Install Ansible Core

      [root@ansible-master ~]# dnf install ansible-core -y




Step 4: Verify Installation

[root@ansible-master ~]# ansible --version

‚úÖ Expected Output:

      ansible [core 2.14.18]
        config file = /etc/ansible/ansible.cfg
        configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
        ansible python module location = /usr/lib/python3.9/site-packages/ansible
        ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
        executable location = /usr/bin/ansible
        python version = 3.9.23 (main, Aug 19 2025, 00:00:00) [GCC 11.5.0 20240719 (Red Hat 11.5.0-11)] (/usr/bin/python3)
        jinja version = 3.1.2
        libyaml = True




Step 5: Create a Working Directory

      [root@ansible-master ~]# mkdir -p /etc/ansible
      [root@ansible-master ~]# cd /etc/ansible
      







[root@ansible-master ~]# dnf install -y python3 python3-pip
[root@ansible-master ~]# python3 --version
pip3 --version
            Python 3.9.23
            pip 21.3.1 from /usr/lib/python3.9/site-packages/pip (python 3.9)


[root@centos-node1 ~]# dnf install -y python3 python3-pip
[root@centos-node1 ~]# python3 --version
Python 3.9.23


root@ubuntu-node2:~# apt update -y
root@ubuntu-node2:~# apt install -y python3 python3-pip
root@ubuntu-node2:~# pip3 --version
            pip 25.0 from /usr/lib/python3/dist-packages/pip (python 3.13)
root@ubuntu-node2:~# python3 --version
            Python 3.13.3



Granting ROOT privliges to user=max
---------------------------------------

            [root@ansible-master ~]# a
            root    ALL=(ALL)       ALL
            max     ALL=(ALL)       ALL            <<<<<<<<<<<<<<<<<<<<
            
            
            
            [root@centos-node1 ~]# vi /etc/sudoers
            root    ALL=(ALL)       ALL
            max     ALL=(ALL)       ALL            <<<<<<<<<<<<<<<<<<<<
            
            
            root@ubuntu-node2:~# v
            root    ALL=(ALL)       ALL
            max     ALL=(ALL)       ALL            <<<<<<<<<<<<<<<<<<<<
            

===================================================================================
üß™ Lab 4 ‚Äî Setting Up Managed Nodes and SSH Key-Based Authentication
===================================================================================


üéØ Objective

Configure secure, passwordless SSH communication between the Ansible control node and all managed nodes.






üß± Lab Setup

| **Host**         | **IP Address** | **Role**     | **OS**          |
| ---------------- | -------------- | ------------ | --------------- |
| `ansible-master` | 192.168.5.80   | Control Node | CentOS Stream 9 |
| `centos-node1`   | 192.168.5.81   | Managed Node | CentOS Stream 9 |
| `ubuntu-node2`   | 192.168.5.83   | Managed Node | Ubuntu 22.04    |







‚öôÔ∏è Step-by-Step Procedure
Step 1: Verify SSH Service on All Nodes

On each managed node, make sure SSH is running:

            # CentOS
            systemctl enable --now sshd
            
            # Ubuntu
            systemctl enable --now ssh
            
            Check status:
            systemctl status sshd
            


[root@centos-node1 ~]# dnf install -y openssh-server
[root@centos-node1 ~]# systemctl enable --now sshd
[root@centos-node1 ~]# systemctl status sshd | grep running
     Active: active (running) since Fri 2025-11-14 23:19:52 UTC; 9s ago



root@ubuntu-node2:~# systemctl enable --now ssh
root@ubuntu-node2:~# systemctl status sshd | grep running
     Active: active (running) since Fri 2025-11-14 01:01:35 UTC; 22h ago









Step 2: From the Control Node, Generate SSH Key Pair
            ssh-keygen -t rsa -b 4096

Press Enter for default paths and no passphrase.


                  [root@ansible-master ~]# ssh-keygen -t rsa -b 4096      <<<<<<<<<<<<<<<<<<<<<<<
                  Generating public/private rsa key pair.
                  Enter file in which to save the key (/root/.ssh/id_rsa): 
                  Enter passphrase for "/root/.ssh/id_rsa" (empty for no passphrase): 
                  Enter same passphrase again: 
                  Your identification has been saved in /root/.ssh/id_rsa
                  Your public key has been saved in /root/.ssh/id_rsa.pub
                  The key fingerprint is:
                  SHA256:I5wrzRdQLdbfU1/8RYFqpAA3uwfwxc4UpoA1wNVhhFo root@ansible-master
                  The key's randomart image is:
                  +---[RSA 4096]----+
                  |  ..=B=*+*.   .+o|
                  |   o EB+Ooo. .  =|
                  |    o .*=.o... .=|
                  |   . . oo+ o. o o|
                  |      +.S..    . |
                  |     o o.o       |
                  |    . + .        |
                  |     . .         |
                  |                 |
                  +----[SHA256]-----+
                  [root@ansible-master ~]# 






[root@centos-node1 ~]# ls .ssh/
[root@centos-node1 ~]# 

root@ubuntu-node2:~# ls .ssh/
root@ubuntu-node2:~#


      [root@centos-node1 ~]# useradd max
      [root@centos-node1 ~]# passwd max

                  root@ubuntu-node2:~# adduser max
                  Retype new password: 
                  passwd: password updated successfully
                  Changing the user information for max
                  Enter the new value, or press ENTER for the default
                          Full Name []: Max Thapa
                          Room Number []: 22
                          Work Phone []: 9865093594
                          Home Phone []: 
                          Other []: 
                  Is the information correct? [Y/n] y








Step 3: Copy the SSH Key to Managed Nodes
            ssh-copy-id root@192.168.5.81   <<<<<<<<<<<<<<<< root cannot login / go by user= max
            ssh-copy-id root@192.168.5.83

When prompted, enter the node‚Äôs password once.
After this, passwordless authentication is established.



                  
                  [root@ansible-master ~]# ssh max@192.168.5.81
                  max@192.168.5.81's password: 
                  Last login: Fri Nov 14 23:25:29 2025 from 192.168.5.80
                  [max@centos-node1 ~]$
                  
                  
                                          [root@ansible-master ~]# ssh max@192.168.5.83
                                          max@192.168.5.83's password: 
                                          Welcome to Ubuntu 25.04 (GNU/Linux 6.8.12-9-pve x86_64)
                                          
                                           * Documentation:  https://help.ubuntu.com
                                           * Management:     https://landscape.canonical.com
                                           * Support:        https://ubuntu.com/pro
                                          Last login: Fri Nov 14 23:35:05 2025 from 192.168.5.80
                                          max@ubuntu-node2:~$ 




            
            [root@ansible-master ~]# ssh-copy-id max@192.168.5.81
            max@192.168.5.81's password: 
            
            [root@ansible-master ~]# ssh-copy-id max@192.168.5.81
            
            


Step 4: Test SSH Connection
            ssh root@centos-node1
            ssh root@ubuntu-node2


‚úÖ If you can log in without password, the setup is correct.
Exit back to master node using:





                  
                  [root@ansible-master ~]# ssh max@192.168.5.81
                  Last login: Fri Nov 14 23:30:33 2025 from 192.168.5.80
                  [max@centos-node1 ~]$ hostname
                  centos-node1
                  [max@centos-node1 ~]$ hostname -I
                  192.168.5.81 
                  [max@centos-node1 ~]$ 
                  
                  
                  
                  
                  
                  
                                    [root@ansible-master ~]# ssh max@192.168.5.83
                                    Welcome to Ubuntu 25.04 (GNU/Linux 6.8.12-9-pve x86_64)
                                    
                                     * Documentation:  https://help.ubuntu.com
                                     * Management:     https://landscape.canonical.com
                                     * Support:        https://ubuntu.com/pro
                                    Last login: Fri Nov 14 23:36:29 2025 from 192.168.5.80
                                    max@ubuntu-node2:~$ whoami
                                    max
                                    max@ubuntu-node2:~$ hostname
                                    ubuntu-node2
                                    max@ubuntu-node2:~$ hostname -I
                                    192.168.5.83 
                                    max@ubuntu-node2:~$







Step 5: Create and Verify Inventory File

                  Create /etc/ansible/hosts:
                  
                              nano /etc/ansible/hosts
                  
                  
                  Add:
                  
                              [all]
                              centos-node1 ansible_host=192.168.5.81
                              ubuntu-node2 ansible_host=192.168.5.83
                  
                  
                  Save and exit.
                  






===================================================================================
‚úÖ Short Summary Table ‚Äì Lab 3 & Lab 4
===================================================================================


üß™ LAB 3 ‚Äî Installing & Verifying Ansible on Control Node
---------------------------------------------------------------------------------------------------------
| **Step**           | **Command / Action**                            | **Notes / Expected Output**     |
| ------------------ | ----------------------------------------------- | ------------------------------- |
| Update system      | `dnf update -y`                                 | Refresh packages                |
| Enable EPEL        | `dnf install epel-release -y`                   | Required for Ansible            |
| Install Ansible    | `dnf install ansible-core -y`                   | Installs core engine            |
| Verify Ansible     | `ansible --version`                             | Shows version, python path, cfg |
| Create Ansible dir | `mkdir -p /etc/ansible`                         | Working directory               |
| Install Python     | `dnf install -y python3 python3-pip`            | Python 3.9.x + pip              |
| Verify Python      | `python3 --version` / `pip3 --version`          | Confirms Python is ready        |
| CentOS Node Python | `dnf install -y python3 python3-pip`            | Needed for Ansible modules      |
| Ubuntu Node Python | `apt install -y python3 python3-pip`            | Python 3.13 available           |
| Create user max    | `useradd max` (CentOS) / `adduser max` (Ubuntu) | For non-root Ansible            |
| Give sudo          | Add to `/etc/sudoers`: `max ALL=(ALL) ALL`      | Grants privilege                |




üß™ LAB 4 ‚Äî Setting Up Managed Nodes & SSH Authentication
-------------------------------------------------------------------

| **Step**             | **Command / Action**                                              | **Notes / Expected Output**         |                     |
| -------------------- | ----------------------------------------------------------------- | ----------------------------------- | ------------------- |
| Install SSH (CentOS) | `dnf install -y openssh-server`                                   | Required for remote mgmt            |                     |
| Start SSH (CentOS)   | `systemctl enable --now sshd`                                     | Status: **active (running)**        |                     |
| Start SSH (Ubuntu)   | `systemctl enable --now ssh`                                      | SSH active                          |                     |
| Verify running       | `systemctl status sshd                                            | grep running`                       | Shows running state |
| Create user max      | `useradd max` / `adduser max`                                     | Same username across nodes          |                     |
| SSH into node        | `ssh max@192.168.5.81` `ssh max@192.168.5.83`                     | Works with password                 |                     |
| Copy SSH key         | `ssh-copy-id max@192.168.5.81` <br>`ssh-copy-id max@192.168.5.83` | After this ‚Üí **passwordless login** |                     |
| Test SSH login       | `ssh max@centos-node1` <br>`ssh max@ubuntu-node2`                 | No password prompt                  |                     |
| Verify hostnames     | `hostname` / `hostname -I`                                        | Confirms correct nodes              |                     |
| Create inventory     | `/etc/ansible/hosts`                                              | Defines managed hosts               |                     |






Inventory File

[all]
centos-node1 ansible_host=192.168.5.81
ubuntu-node2 ansible_host=192.168.5.83
























===================================================================================
üß™ Lab 5 ‚Äî First Ansible Command Using the ping Module
===================================================================================


üéØ Objective

Use the Ansible ping module to verify that the control node (ansible-master) can 
successfully communicate with all managed nodes over SSH and Python.

This confirms:
            SSH access
            Python installed correctly
            Inventory file working
            User authentication successful
            



‚öôÔ∏è Step-by-Step Procedure

Step 1 ‚Äî Navigate to /etc/ansible

      [max@ansible-master ~]$ cat /etc/ansible/hosts | grep 192.168.5
      centos-node1 ansible_host=192.168.5.81
      ubuntu-node2 ansible_host=192.168.5.83


Step 2 ‚Äî Run the First Ansible Ping Command

            This command tests all hosts in the all group:
            
            [max@ansible-master ~]$ ansible all -m ping -u max --become
            
            
            [max@ansible-master ~]$  ansible all -m ping -u max
                              ubuntu-node2 | SUCCESS => {
                                  "ansible_facts": {
                                      "discovered_interpreter_python": "/usr/bin/python3"
                                  },
                                  "changed": false,
                                  "ping": "pong"
                              }
                              centos-node1 | SUCCESS => {
                                  "ansible_facts": {
                                      "discovered_interpreter_python": "/usr/bin/python3"
                                  },
                                  "changed": false,
                                  "ping": "pong"
                              }
            
            
            
            [max@ansible-master ~]$  ansible all -m ping -u max  --ask-become-pass
            BECOME password:
            ubuntu-node2 | SUCCESS => {
            




===================================================================================
üß™ Lab 6 ‚Äî Creating and Managing an Ansible Inventory File (Static Hosts)
===================================================================================


üéØ Objective

Learn how to create, organize, and manage a static Ansible inventory file
that defines all managed nodes (CentOS, Ubuntu) with hostnames and IP addresses.

By the end of this lab you will:
            Understand Ansible inventory structure
            Create a static /etc/ansible/hosts file
            Define hosts, groups, variables
            Test inventory using Ansible commands


| **Host**         | **IP Address** | **Role**     | **User** |
| ---------------- | -------------- | ------------ | -------- |
| `ansible-master` | 192.168.5.80   | Control Node | max      |
| `centos-node1`   | 192.168.5.81   | Managed Node | max      |
| `ubuntu-node2`   | 192.168.5.83   | Managed Node | max      |



‚öôÔ∏è Step-by-Step Procedure

Step 1 ‚Äî Navigate to the Ansible Directory
            cd /etc/ansible
            
            
            If the folder doesn‚Äôt exist:
            
            sudo mkdir -p /etc/ansible






Step 2 ‚Äî Create the Inventory File

                  Open the hosts file:
                  
                        sudo nano /etc/ansible/hosts
                  
                  Add the following:
                  
                        [all]
                        centos-node1 ansible_host=192.168.5.81
                        ubuntu-node2 ansible_host=192.168.5.83
                  
                  
                  ‚úîÔ∏è This means:
                  
                              centos-node1 ‚Üí 192.168.5.81
                              
                              ubuntu-node2 ‚Üí 192.168.5.83
                  
                  Save and exit.








Step 3 ‚Äî Test Inventory Parsing
           
      [max@ansible-master ~]$ ansible all --list-hosts
        hosts (2):
          centos-node1
          ubuntu-node2

            
            
     

Create Host Groups
-----------------------------
                  Open /etc/ansible/hosts again:
                  
                  [max@ansible-master ~]$ vi /etc/ansible/hosts                             
                  
                  [centos]
                  centos-node1 ansible_host=192.168.5.81
                  
                  [ubuntu]
                  ubuntu-node2 ansible_host=192.168.5.83
                  
                  [allnodes:children]
                  centos
                  ubuntu





[max@ansible-master ~]$ ansible centos-node1 -m ping -u max
centos-node1 | SUCCESS => {


[max@ansible-master ~]$ ansible centos -m ping -u max
centos-node1 | SUCCESS => {




[max@ansible-master ~]$ ansible ubuntu -m ping -u max
ubuntu-node2 | SUCCESS => {




[max@ansible-master ~]$ ansible allnodes:children -m ping -u max
[WARNING]: Could not match supplied host pattern, ignoring: children
ubuntu-node2 | SUCCESS => {









Check uptime
---------------------
[max@ansible-master ~]$ ansible all -m command -a "uptime" -u max
ubuntu-node2 | CHANGED | rc=0 >>
 06:15:47 up 1 day,  5:14,  3 users,  load average: 0.25, 0.14, 0.05
centos-node1 | CHANGED | rc=0 >>
 06:15:47 up 1 day,  5:14,  3 users,  load average: 0.25, 0.14, 0.05



[max@ansible-master ~]$ ansible all -m command -a "whoami" -u max
ubuntu-node2 | CHANGED | rc=0 >>
max
centos-node1 | CHANGED | rc=0 >>
max





[max@ansible-master ~]$ ansible all -m command -a "hostname" -u max
ubuntu-node2 | CHANGED | rc=0 >>
ubuntu-node2
centos-node1 | CHANGED | rc=0 >>
centos-node1




[max@ansible-master ~]$ ansible all -m command -a "date" -u max
ubuntu-node2 | CHANGED | rc=0 >>
Sat Nov 15 06:19:05 UTC 2025
centos-node1 | CHANGED | rc=0 >>
Sat Nov 15 06:19:05 AM UTC 2025





[max@ansible-master ~]$ ansible all -m command -a "cat /etc/os-release" -u max
                  ubuntu-node2 | CHANGED | rc=0 >>
                  PRETTY_NAME="Ubuntu 25.04"
                  NAME="Ubuntu"
                  VERSION_ID="25.04"
                  VERSION="25.04 (Plucky Puffin)"
                  VERSION_CODENAME=plucky
                  ID=ubuntu
                  ID_LIKE=debian
                  HOME_URL="https://www.ubuntu.com/"
                  SUPPORT_URL="https://help.ubuntu.com/"
                  BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
                  PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
                  UBUNTU_CODENAME=plucky
                  LOGO=ubuntu-logo
                  
                  
                  centos-node1 | CHANGED | rc=0 >>
                  NAME="CentOS Stream"
                  VERSION="9"
                  ID="centos"
                  ID_LIKE="rhel fedora"
                  VERSION_ID="9"
                  PLATFORM_ID="platform:el9"
                  PRETTY_NAME="CentOS Stream 9"
                  ANSI_COLOR="0;31"
                  LOGO="fedora-logo-icon"
                  CPE_NAME="cpe:/o:centos:centos:9"
                  HOME_URL="https://centos.org/"
                  BUG_REPORT_URL="https://issues.redhat.com/"
                  REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux 9"
                  REDHAT_SUPPORT_PRODUCT_VERSION="CentOS Stream"



[max@ansible-master ~]$ ansible all -m command -a "df -h" -u max
ubuntu-node2 | CHANGED | rc=0 >>
Filesystem                        Size  Used Avail Use% Mounted on
/dev/mapper/pve-vm--207--disk--0   15G  1.2G   13G   9% /
none                              492K  4.0K  488K   1% /dev
efivarfs                          128K   58K   66K  47% /sys/firmware/efi/efivars
tmpfs                              32G     0   32G   0% /dev/shm
tmpfs                              13G  136K   13G   1% /run
tmpfs                              32G   96K   32G   1% /tmp
tmpfs                             5.0M     0  5.0M   0% /run/lock
tmpfs                             6.3G  8.0K  6.3G   1% /run/user/1000


centos-node1 | CHANGED | rc=0 >>
Filesystem                        Size  Used Avail Use% Mounted on
/dev/mapper/pve-vm--206--disk--0   15G  549M   14G   4% /
none                              492K  4.0K  488K   1% /dev
udev                               32G     0   32G   0% /dev/tty
tmpfs                              32G     0   32G   0% /dev/shm
tmpfs                              13G  8.2M   13G   1% /run
tmpfs                             6.3G     0  6.3G   0% /run/user/1000








[max@ansible-master ~]$ ansible all -m command -a "free -h" -u max
ubuntu-node2 | CHANGED | rc=0 >>
               total        used        free      shared  buff/cache   available
Mem:           1.0Gi       133Mi       136Mi       204Ki       753Mi       890Mi
Swap:          1.0Gi        52Ki       1.0Gi
centos-node1 | CHANGED | rc=0 >>
               total        used        free      shared  buff/cache   available
Mem:           1.0Gi        73Mi       707Mi       8.0Mi       251Mi       950Mi
Swap:          1.0Gi          0B       1.0Gi








[max@ansible-master ~]$ ansible all -m command -a "hostname" -u max
                  ubuntu-node2 | CHANGED | rc=0 >>
                  ubuntu-node2
                  centos-node1 | CHANGED | rc=0 >>
                  centos-node1
                  



[max@ansible-master ~]$ ansible all -m command -a "hostname -I" -u max
                  ubuntu-node2 | CHANGED | rc=0 >>
                  192.168.5.83
                  centos-node1 | CHANGED | rc=0 >>
                  192.168.5.81





[max@ansible-master ~]$ ansible all -m command -a "ip route" -u max
            ubuntu-node2 | CHANGED | rc=0 >>
            default via 192.168.5.1 dev eth0 proto dhcp src 192.168.5.83 metric 1024
            192.168.4.0/22 dev eth0 proto kernel scope link src 192.168.5.83 metric 1024
            192.168.5.1 dev eth0 proto dhcp scope link src 192.168.5.83 metric 1024
            
            
            centos-node1 | CHANGED | rc=0 >>
            default via 192.168.5.1 dev eth0 proto dhcp src 192.168.5.81 metric 100
            192.168.4.0/22 dev eth0 proto kernel scope link src 192.168.5.81 metric 100









[max@ansible-master ~]$ ansible all -m command -a "ss -tnl" -u max
                        ubuntu-node2 | CHANGED | rc=0 >>
                        State  Recv-Q Send-Q Local Address:Port Peer Address:Port
                        LISTEN 0      4096         0.0.0.0:22        0.0.0.0:*
                        LISTEN 0      4096      127.0.0.54:53        0.0.0.0:*
                        LISTEN 0      100        127.0.0.1:25        0.0.0.0:*
                        LISTEN 0      4096   127.0.0.53%lo:53        0.0.0.0:*
                        LISTEN 0      100            [::1]:25           [::]:*
                        LISTEN 0      4096            [::]:22           [::]:*
                        
                        
                        centos-node1 | CHANGED | rc=0 >>
                        State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess
                        LISTEN 0      128          0.0.0.0:22        0.0.0.0:*
                        LISTEN 0      128             [::]:22           [::]:*







üèÅ Best Quick Test Commands (Top 10)
-----------------------------

Use these 10 commands anytime to verify a node:

            ansible all -m ping -u max --become
            
            ansible all -m command -a "whoami" -u max --become
            
            ansible all -m command -a "hostname" -u max --become
            
            ansible all -m command -a "uptime" -u max --become
            
            ansible all -m command -a "df -h" -u max --become
            
            ansible all -m command -a "free -h" -u max --become
            
            ansible all -m command -a "ip a" -u max --become
            
            ansible all -m command -a "ss -tuln" -u max --become
            
            ansible all -m shell -a "echo Hello from $(hostname)" -u max --become
            
            ansible all -m setup -u max --become







===================================================================================
üß™ Lab 7 ‚Äî Running Simple Ad-hoc Commands for Package and Service Management
===================================================================================

üéØ Objective

This lab teaches you how to use Ansible ad-hoc commands to:
      Install and remove packages
      Start, stop, enable, restart services
      Verify service status
      Perform package updates
      Manage services on CentOS and Ubuntu nodes
      

| **Host**       | **IP Address** | **OS**               | **User** | **Notes**         |
| -------------- | -------------- | -------------------- | -------- | ----------------- |
| `centos-node1` | 192.168.5.81   | CentOS Stream 9      | max      | Uses `yum` module |
| `ubuntu-node2` | 192.168.5.83   | Ubuntu 22.04 / 25.04 | max      | Uses `apt` module |
| Control Node   | 192.168.5.80   | CentOS               | max      | Ansible installed |





‚öôÔ∏è Step-by-Step Procedure
-----------------------------------
‚úÖ Part 1 ‚Äî Package Management (Install / Remove / Update)
üåê A. Install a Package on CentOS Node

                        Example package: tree
                        
                        ansible centos -m yum -a "name=tree state=present" -u max --become
                        
                        Expected Output:
                        centos-node1 | CHANGED => { ... }
                        
                        Verify tree installation:
                        ansible centos -m command -a "tree --version" -u max --become




üåê B. Install a Package on Ubuntu Node

            Install htop:
            
            ansible ubuntu -m apt -a "name=htop state=present update_cache=yes" -u max --become
            
            
            Verify:
            
            ansible ubuntu -m command -a "htop --version" -u max --become



üåê C. Remove a Package

CentOS:

ansible centos -m yum -a "name=tree state=absent" -u max --become


Ubuntu:

ansible ubuntu -m apt -a "name=htop state=absent" -u max --become

üåê D. Update All Packages

CentOS:

ansible centos -m yum -a "name=* state=latest" -u max --become


Ubuntu:

ansible ubuntu -m apt -a "upgrade=yes update_cache=yes" -u max --become

‚úÖ Part 2 ‚Äî Service Management (Start / Stop / Enable / Restart)

You can test any service like:

SSH (sshd / ssh)

Cron (crond / cron)

Apache (httpd / apache2)

NTP (chronyd / systemd-timesyncd)

Here are universal examples:

üî• A. Start a Service

CentOS (sshd):

ansible centos -m service -a "name=sshd state=started" -u max --become


Ubuntu (ssh):

ansible ubuntu -m service -a "name=ssh state=started" -u max --become

üî• B. Restart a Service

CentOS:

ansible centos -m service -a "name=sshd state=restarted" -u max --become


Ubuntu:

ansible ubuntu -m service -a "name=ssh state=restarted" -u max --become

üî• C. Stop a Service
ansible all -m service -a "name=cron state=stopped" -u max --become


‚ö†Ô∏è Do NOT stop sshd, or you will disconnect Ansible.

üî• D. Enable Service at Boot

CentOS:

ansible centos -m service -a "name=sshd enabled=yes" -u max --become


Ubuntu:

ansible ubuntu -m service -a "name=ssh enabled=yes" -u max --become

üî• E. Check Service Status
ansible all -m shell -a "systemctl status sshd | grep Active" -u max --become


Ubuntu uses:

ansible ubuntu -m shell -a "systemctl status ssh | grep Active" -u max --become

üìå Extra Useful Ad-hoc Commands
Check system uptime:
ansible all -m command -a "uptime" -u max --become

Check logged-in users:
ansible all -m command -a "who" -u max --become

Check disk usage:
ansible all -m command -a "df -h" -u max --become

Check memory usage:
ansible all -m command -a "free -h" -u max --become






























===================================================================================

===================================================================================






===================================================================================

===================================================================================






===================================================================================

===================================================================================






===================================================================================

===================================================================================






===================================================================================

===================================================================================






===================================================================================

===================================================================================






===================================================================================

===================================================================================






===================================================================================

===================================================================================




