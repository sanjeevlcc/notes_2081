

Who is this course for?
============================
The course is designed for Kubernetes/platform admins, platform/software developers, machine learning engineers, data scientists, data engineers, site reliability engineers, and anyone interested in understanding the anatomy of a machine learning tool kit that harnesses the true power of Kubernetes.



What prerequisites should you have?
=======================================
Kubeflow by its nature is a collaborative solution and growing community. We’d love it if you took this course and found ways to contribute to Kubeflow (more on that later)! In order to set you up for success, we have provided a list of topics that might help you hit the ground running when taking this course. It's not a major issue if you aren’t a SME in these topics, but brushing up on them or reading some of the references we provide might help you digest the content a bit easier. The resources below are meant to be helpful, but are by no means required for the completion of this course.

1. Experience with Cloud Computing

Cloud computing. The concept that has taken over the world. Is it just someone else’s computers? Is it REALLY infinite in scale? The GPU shortage might be bringing us all back to reality when it comes to how fast or large the cloud can scale. That being said, with the rise of technologies like Kubernetes, the cloud is more accessible than ever. Understanding core cloud concepts will help you understand Kubeflow, as well as the distributions we will discuss.

Learn more here:

Introduction to Cloud Infrastructure Technologies (LFS151): a free course offered by the Linux Foundation.
The Engineering Room Ep.13: Kelsey Hightower On Kubernetes & Cloud Computing: a great video of two heavy hitters in this space discussing cloud computing.
Cloudy with a chance of Kelsey Hightower Go Time episode, a great podcast that discusses the origin of Kubernetes.
2. Familiarity with DevOps and Cloud Native Principles

Cloud computing isn’t going anywhere any time soon, but the definition of “cloud native” is tough. It can often be seen as a buzzword and since everyone seems to have their own definition, we asked Google’s Bard for a definition. In theory, Bard pulls from many many sources, so here is how a generative AI tool defines cloud native: “Cloud native builds apps to thrive in the cloud, not just exist. It's about Microservices, Containers, Automation, Resilience, and Observability - think Lego blocks, not monoliths. This shift boosts agility, cuts costs, and keeps users happy, making cloud native the future of building modern apps” The Bard's definition resonates closely with our understanding of what cloud native is all about.  Here are some good resources to learn more and be ready to dive into what makes Kubeflow “cloud native”.

Introduction to DevOps and Site Reliability Engineering (LFS162): a free course offered by the Linux Foundation.
DevOps and SRE Fundamentals (LFS261): a course offered by the Linux Foundation, with hands-on lab exercises.
SRE for Everyone Else, with Steve McGhee on the Kubernetes podcast is a great discussion around adopting SRE and release engineering principles.
The SRE handbook is a fantastic resource that even has chapters on data pipelines!
The Phoenix Project: A good book recommendation for the less technical folks or really anyone who has ever worked in a company trying to adopt DevOps.
3. Some Basic Programming Experience with Python

For a good free option, Automate the Boring Stuff is a fantastic resource with hands-on projects to get some Python experience.
A good paid, more structured option for university credits is the Georgia Tech Professional Certificate in Introduction to Python Programming.
4. Experience with Technical Documentation

There is an art to reading technical documentation. It’s such an art form that modern AI strategies are seeking to reduce the need to actually read the docs. The Kubeflow docs are a great place to start if you aren’t used to reading technical documentation. The goal of this course is to help consolidate that information, but diving into the documentation might be helpful.

5. Experience with Open Source Projects in general

Open source is a concept that can be difficult to wrap our heads around. Do people really contribute free code? How do organizations obtain the necessary support for open source software, whether it's for addressing bugs or ensuring reliable performance and security in their deployments? ? Is the software really free? We will discuss these topics a bit more in our distribution section, but some open source software (OSS) fluency might help you engage with the community and other projects at a later date.

Here are some good resources:

The Cathedral and the Bazaar is a famous essay on open source software.
Cloud Native Computing Foundation Official Site discusses how open source projects are managed and supported.
Why Open Source Misses the Point of Free Software is a great GNU blog on open source and the point of free software.
Creating Effective Documentation for Developers (LFC112): a course offered by the Linux Foundation.
Open Source Licensing Basics for Software Developers (LFC191): a course offered by the Linux Foundation.
6. Basic Understanding of Kubernetes and Containers 

For this introductory course, we won't go too deep into Kuberenetes, but this all does run on Kubernetes. Think of Kuberentes as the engine and not the car. Our MLOPs teams are race car drivers. Here are some resources on Kubernetes and containers.

The Official Kubernetes Documentation has all you need to know about Kubernetes. 
Introduction to Kubernetes (LFS158): a free course offered by the Linux Foundation.
Containers Fundamentals (LFS253): a course offered by the Linux Foundation, with hands-on lab exercises.
The Certified Kubernetes Administrator Training Curriculum might give you a good learning path.
What’s a Linux Container (RedHat) is a Red Hat blog with graphics on how containers work.
The cloud computing resources we provided above will help you with this topic as well!







What does it prepare you for?
===============================
This introductory course unveils the potential of Kubeflow, an open source platform revolutionizing Machine Learning (ML) deployment. Through a blend of theoretical foundations and practical video walkthroughs, you'll gain critical insights into:

The landscape of ML development and deployment challenges
Kubeflow's architecture and key components
Data preparation, model training, serving, and management within Kubeflow
Integrating Kubeflow with existing software tools and cloud environments
Best practices for MLOps and model lifecycle management
Gaining confidence in these foundational concepts will empower you to contribute to the vibrant Kubeflow community, engage in further exploration, and apply your newfound knowledge to real-world ML projects




What does it NOT prepare you for?
======================================
This course is an introduction to Kubeflow and machine learning operations and is not designed to discuss the deeper operationalizations of Kubeflow and the nitty gritty implementation details. This course is also not designed to tell you how to prevent hallucinations in your LLMs or deploy ethical applications, but will give you the tools to explore those concepts based on your desired outcomes.




How is the course formatted?
================================
In order to make it easier to distinguish the various types of content in the course, we use the color coding and formats below:

Dark blue: Text typed at the command line

Green: Output

Black: File content

Brown: File/Directory names

Light blue: Hyperlink















Meet Your Instructor: Chase Christensen
============================================
Chase is a presales engineer, and solutions architect focused on helping organizations drive value from the tools they are exploring or integrating. Chase began his career in QA testing, where he developed an appreciation for automated testing and deployment. From there, he was responsible for a multi-vendor, multi-platform hybrid research and innovation lab at the vendor-added reseller Insight, where he was introduced to Kubernetes. He achieved the CKA, CKAD, and CKS certifications and decided to pivot to the ML world on Kubernetes by joining the Arrikto Enterprise Kubeflow team. He believes in open source as a transparent and people-centric approach to driving value for data professionals and (although no longer at Arrikto) has been working with organizations adopting Kubeflow and training internal teams on Kubeflow as a project for three years. During his free time, he enjoys hiking and exploring the Colorado wilderness.

Special Thanks:
A special thanks to Ben Reutter for the multi-media support! We couldn't have delivered such high-quality video content without him. Thank you Ben!







Linux Foundation
============================
The Linux Foundation is the world’s leading home for collaboration on open source software, hardware, standards, and data. Linux Foundation projects are critical to the world’s infrastructure, including Linux, Kubernetes, Node.js, ONAP, PyTorch, RISC-V, SPDX, OpenChain, and more. The Linux Foundation focuses on leveraging best practices and addressing the needs of contributors, users, and solution providers to create sustainable models for open collaboration. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see its trademark usage page. Linux is a registered trademark of Linus Torvalds.






Linux Foundation Events
================================ https://events.linuxfoundation.org/

Over 85,000 open source technologists and leaders worldwide gather at Linux Foundation events annually to share ideas, learn and collaborate. Linux Foundation events are the meeting place of choice for open source maintainers, developers, architects, infrastructure managers, and sysadmins and technologists leading open source program offices, and other critical leadership functions.

These events are the best place to gain visibility within the open source community quickly and advance open source development work by forming connections with the people evaluating and creating the next generation of technology. They provide a forum to share and gain knowledge, help organizations identify software trends early to inform future technology investments, connect employers with talent, and showcase technologies and services to influential open source professionals, media, and analysts around the globe.

To learn more about the Linux Foundation events and to register, click here.






Linux Foundation Education
================================
https://training.linuxfoundation.org/?_gl=1%2A1a0zr5m%2A_gcl_au%2ANjU4OTY3MjE0LjE3MzA3MDI4ODY.%2A_ga%2AODkxMTgyNjEwLjE3MjI4MjQ3Nzc.%2A_ga_EMX7DDZMX4%2AMTczNDUxNjAyNS45LjEuMTczNDUxODI0MC42MC4wLjA.


The Linux Foundation Education Group works with expert instructors and experienced open source developers to create training courses for every level of experience, from complete newbies to veteran developers, as well as certification exams which demonstrate your skills to potential employers in a trusted verifiable way.

To get more information about specific courses and certification exams offered by the Linux Foundation, including technical requirements and other logistics, visit the Linux Foundation Education website.









https://www.youtube.com/watch?v=jwG5sXJzC-c




























********************************************************************
********************************************************************
02. The Model Application Relationship and the Power 
of Reproducibility

********************************************************************
********************************************************************




Chapter Overview
================================

Welcome! This course will prepare you for an exciting new role within the data world, whether that be a data scientist, machine learning engineer, or any other machine learning operations (MLOPs) role. The first path to success as a part of a machine learning-oriented team is understanding the landscape of machine learning development and deployment challenges. Still, since that topic is complex, we will take it one step at a time.





Learning Objectives
================================

By the end of this chapter, you should be able to:

Discuss the importance of reproducibility and replicability.
Explain the value behind applications' containerization in the context of replicability, reproducibility, and model deployment.
Discuss the model and application relationship.
Define the term “features” in the context of ML/AI.


Model or Application?
================================


Models and applications both work together to drive better business outcomes. New data professionals often have questions about how models and applications are related. Do we need applications if we have models? Do models replace the role of developers? This section will answer those questions by exploring how applications and models work together.









What is a Model?
================================


A model takes data as a request and responds with a prediction based on learned patterns. Just like your brain tries to connect something it observes within the context of your life, the model takes in data and processes it to predict using its training experience. One typical example is a recommendation engine. A recommendation engine is a model that learns from your choices, like the movies you watch, to predict and suggest new ones you might like. It's like a friend who knows your tastes and recommends films based on what you've enjoyed. This engine constantly improves its suggestions by learning from your viewing history. In a recommendation model, the data includes user interaction data, such as items viewed, purchased, or rated; user demographic information; item attributes, like genre, author, and release date for movies or books; and sometimes contextual information, like the time of day or location. The prediction output contains items the user will likely be interested in. This prediction is based on analyzing the data to understand user preferences and behavior patterns and applying them to a distribution. In a movie recommendation system, the prediction could be the movies the user will likely enjoy watching based on their past viewing history and preferences.




7 Types of Statistical Distributions
with Practical Examples

https://datasciencedojo.com/blog/types-of-statistical-distributions-in-ml/













Unpacking Predictions
================================


We have seen some need to clarify the term prediction when learning about machine learning predictions. A prediction is a formatted (often JSON, tensors, or arrays) response from the model to the application. The world of large language models like ChatGPT makes this even more confusing because the prediction can be a human-like text response rather than a simple numerical score or a class label typically expected from traditional models. In machine learning, a prediction is the output generated by a model after it has been trained on a dataset and then provided with new, unseen data. The nature of this output varies significantly depending on the model type and the specific task. For example, the prediction could be a category or label in a classification task, whereas in a regression task, it would be a continuous value.


https://www.ml-science.com/array








Types of Models
================================

A recommendation engine is only one type of model. The input data format and the output prediction depend on the model and use case. Some models, like recommendation engines, often use a mix of techniques.


            Model Examples
            
            Expand Regression Models
            Expand Classification Models
            Expand Clustering Models
            Expand Time Series Models
            Expand Dimensionality Reduction Models
            Expand Neural Networks


        Regression Models
        For predicting continuous values, like sales forecasting or determining price trends.
        
        
        
        
        
        Close Classification Models
        Aimed at categorizing data into predefined classes, such as spam detection in emails or image recognition.
        
        
        
        
        
        Close Clustering Models
        These models identify inherent groupings in data, which are helpful in market segmentation or organizing large data sets.
        
        
        
        
        
        
        
        
        
        Close Time Series Models
        Specialized in analyzing time-ordered data to forecast future points in the series, like stock prices or weather predictions.
        
        
        
        
        
        
        
        Close Dimensionality Reduction Models
        Used to simplify data, reduce its complexity, and retain essential features, often used in data visualization.
        
        
        
        
        
        
        
        Close Neural Networks
        Inspired by the human brain, these models can learn complex patterns through layers of interconnected nodes, pivotal in deep learning applications like language translation or autonomous vehicles.
        
        
        





Are Models the Full Story?
================================


The model is only part of the story regarding building intelligent applications. The model acts as the brain for our application. The application uses the model's response to determine logical flow, much like a human uses their brain to analyze a situation before using their body to execute their brain's determined actions. The application's logic is implemented based on the context of the model's outputs. The model application relationship is something that people new to the ML/AI world often find surprising. This surprise derives from their experience with the traditional software flow, where a developer finds patterns and uses data and code to drive an outcome. Data science teams take data and the determined outcome, then write code to build an algorithms-powered model. Instead of a developer hardcoding the desired inputs and outputs, the model learns patterns based on the data. The model also tests itself on how well it learned a concept and improved its known patterns during the training process—much like many of us do when studying for an exam or certification. We will go deeper into the model development lifecycle in future chapters.









Our Sample Application
================================


Pretend for a second that we are making an application whose job is to determine if a picture is or is not a duck and then sort the duck images into a “book of ducks.” Suppose you just went on a trip with your duck-loving friend and took 3000 pictures of waterfowl. You want to surprise your friend with a book of photographs containing all the ducks you encountered on your trip. However, you do not want to ruin the surprise by having your friend identify and sort the pictures. You also want to ensure this model works for others identifying ducks and potentially growing the duck-finding community! How might we go about this?









Duck Detection Application Attempt
================================


How would we start building our duck detection application without machine learning? The traditional software engineer might start by writing several loops and functions, attempting to find all the characteristics (or features) that identify a duck.

The code might look like the following:

// Pseudocode for Duck-or-Not-Duck Image Recognition
// Define the main function
function isItADuck(image):
    // Step 1: Check if the image is in the correct format
    if not isValidImageFormat(image):
    return "Error: Invalid image format. Please upload a JPG or PNG."

    // Step 2: Analyze the color spectrum of the image
    predominantColors = analyzePredominantColors(image)
    if "yellow" not in predominantColors:
    return "Probably not a duck. Ducks are often yellow."

    // Step 3: Look for the shape of a beak
    if not detectShape(image, "beak"):
    return "Probably not a duck. No beak detected."

    // Step 4: Check for presence of webbed feet
    if not detectShape(image, "webbed feet"):
    return "Might be a duck, but can't confirm without seeing webbed feet."

    // Step 5: Analyze the image for quacking sounds (just being silly)
    if detectSound(image, "quack"):
    return "Definitely a duck. It quacks!"

    // Step 6: Use advanced duck detection logic (very pseudo)
    if advancedDuckDetectionAlgorithm(image):
    return "Based on advanced analysis, this is indeed a duck."
    // If all else fails
    return "Uncertain if this is a duck. Please consult your duck watcher friend.".

A duck detection model may seem like a silly example, but let’s consider it for a moment. The pseudo application contained a loop that ended with consult your duck watcher friend, included some complex shape detection, and implemented advancedDuckDetectionAlgorithms. That code would be tricky to support. Identifying all possible images with and without ducks would be even more challenging. Imagine all the positions, environments, and quality of duck photos. An expert may also need to be consulted to identify many pictures, which can become complicated and expensive, defeating the application's purpose.








================================




================================


********************************************************************
********************************************************************
xx
********************************************************************
********************************************************************

================================




================================




================================




================================




================================




