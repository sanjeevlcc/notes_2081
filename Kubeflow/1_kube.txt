






********************************************************************
********************************************************************

01. Course Introduction

********************************************************************
********************************************************************




Who is this course for?
============================
The course is designed for Kubernetes/platform admins, platform/software developers, machine learning engineers, data scientists, data engineers, site reliability engineers, and anyone interested in understanding the anatomy of a machine learning tool kit that harnesses the true power of Kubernetes.



What prerequisites should you have?
=======================================
Kubeflow by its nature is a collaborative solution and growing community. We’d love it if you took this course and found ways to contribute to Kubeflow (more on that later)! In order to set you up for success, we have provided a list of topics that might help you hit the ground running when taking this course. It's not a major issue if you aren’t a SME in these topics, but brushing up on them or reading some of the references we provide might help you digest the content a bit easier. The resources below are meant to be helpful, but are by no means required for the completion of this course.

1. Experience with Cloud Computing

Cloud computing. The concept that has taken over the world. Is it just someone else’s computers? Is it REALLY infinite in scale? The GPU shortage might be bringing us all back to reality when it comes to how fast or large the cloud can scale. That being said, with the rise of technologies like Kubernetes, the cloud is more accessible than ever. Understanding core cloud concepts will help you understand Kubeflow, as well as the distributions we will discuss.

Learn more here:

Introduction to Cloud Infrastructure Technologies (LFS151): a free course offered by the Linux Foundation.
The Engineering Room Ep.13: Kelsey Hightower On Kubernetes & Cloud Computing: a great video of two heavy hitters in this space discussing cloud computing.
Cloudy with a chance of Kelsey Hightower Go Time episode, a great podcast that discusses the origin of Kubernetes.
2. Familiarity with DevOps and Cloud Native Principles

Cloud computing isn’t going anywhere any time soon, but the definition of “cloud native” is tough. It can often be seen as a buzzword and since everyone seems to have their own definition, we asked Google’s Bard for a definition. In theory, Bard pulls from many many sources, so here is how a generative AI tool defines cloud native: “Cloud native builds apps to thrive in the cloud, not just exist. It's about Microservices, Containers, Automation, Resilience, and Observability - think Lego blocks, not monoliths. This shift boosts agility, cuts costs, and keeps users happy, making cloud native the future of building modern apps” The Bard's definition resonates closely with our understanding of what cloud native is all about.  Here are some good resources to learn more and be ready to dive into what makes Kubeflow “cloud native”.

Introduction to DevOps and Site Reliability Engineering (LFS162): a free course offered by the Linux Foundation.
DevOps and SRE Fundamentals (LFS261): a course offered by the Linux Foundation, with hands-on lab exercises.
SRE for Everyone Else, with Steve McGhee on the Kubernetes podcast is a great discussion around adopting SRE and release engineering principles.
The SRE handbook is a fantastic resource that even has chapters on data pipelines!
The Phoenix Project: A good book recommendation for the less technical folks or really anyone who has ever worked in a company trying to adopt DevOps.
3. Some Basic Programming Experience with Python

For a good free option, Automate the Boring Stuff is a fantastic resource with hands-on projects to get some Python experience.
A good paid, more structured option for university credits is the Georgia Tech Professional Certificate in Introduction to Python Programming.
4. Experience with Technical Documentation

There is an art to reading technical documentation. It’s such an art form that modern AI strategies are seeking to reduce the need to actually read the docs. The Kubeflow docs are a great place to start if you aren’t used to reading technical documentation. The goal of this course is to help consolidate that information, but diving into the documentation might be helpful.

5. Experience with Open Source Projects in general

Open source is a concept that can be difficult to wrap our heads around. Do people really contribute free code? How do organizations obtain the necessary support for open source software, whether it's for addressing bugs or ensuring reliable performance and security in their deployments? ? Is the software really free? We will discuss these topics a bit more in our distribution section, but some open source software (OSS) fluency might help you engage with the community and other projects at a later date.

Here are some good resources:

The Cathedral and the Bazaar is a famous essay on open source software.
Cloud Native Computing Foundation Official Site discusses how open source projects are managed and supported.
Why Open Source Misses the Point of Free Software is a great GNU blog on open source and the point of free software.
Creating Effective Documentation for Developers (LFC112): a course offered by the Linux Foundation.
Open Source Licensing Basics for Software Developers (LFC191): a course offered by the Linux Foundation.
6. Basic Understanding of Kubernetes and Containers 

For this introductory course, we won't go too deep into Kuberenetes, but this all does run on Kubernetes. Think of Kuberentes as the engine and not the car. Our MLOPs teams are race car drivers. Here are some resources on Kubernetes and containers.

The Official Kubernetes Documentation has all you need to know about Kubernetes. 
Introduction to Kubernetes (LFS158): a free course offered by the Linux Foundation.
Containers Fundamentals (LFS253): a course offered by the Linux Foundation, with hands-on lab exercises.
The Certified Kubernetes Administrator Training Curriculum might give you a good learning path.
What’s a Linux Container (RedHat) is a Red Hat blog with graphics on how containers work.
The cloud computing resources we provided above will help you with this topic as well!







What does it prepare you for?
===============================
This introductory course unveils the potential of Kubeflow, an open source platform revolutionizing Machine Learning (ML) deployment. Through a blend of theoretical foundations and practical video walkthroughs, you'll gain critical insights into:

The landscape of ML development and deployment challenges
Kubeflow's architecture and key components
Data preparation, model training, serving, and management within Kubeflow
Integrating Kubeflow with existing software tools and cloud environments
Best practices for MLOps and model lifecycle management
Gaining confidence in these foundational concepts will empower you to contribute to the vibrant Kubeflow community, engage in further exploration, and apply your newfound knowledge to real-world ML projects




What does it NOT prepare you for?
======================================
This course is an introduction to Kubeflow and machine learning operations and is not designed to discuss the deeper operationalizations of Kubeflow and the nitty gritty implementation details. This course is also not designed to tell you how to prevent hallucinations in your LLMs or deploy ethical applications, but will give you the tools to explore those concepts based on your desired outcomes.




How is the course formatted?
================================
In order to make it easier to distinguish the various types of content in the course, we use the color coding and formats below:

Dark blue: Text typed at the command line

Green: Output

Black: File content

Brown: File/Directory names

Light blue: Hyperlink















Meet Your Instructor: Chase Christensen
============================================
Chase is a presales engineer, and solutions architect focused on helping organizations drive value from the tools they are exploring or integrating. Chase began his career in QA testing, where he developed an appreciation for automated testing and deployment. From there, he was responsible for a multi-vendor, multi-platform hybrid research and innovation lab at the vendor-added reseller Insight, where he was introduced to Kubernetes. He achieved the CKA, CKAD, and CKS certifications and decided to pivot to the ML world on Kubernetes by joining the Arrikto Enterprise Kubeflow team. He believes in open source as a transparent and people-centric approach to driving value for data professionals and (although no longer at Arrikto) has been working with organizations adopting Kubeflow and training internal teams on Kubeflow as a project for three years. During his free time, he enjoys hiking and exploring the Colorado wilderness.

Special Thanks:
A special thanks to Ben Reutter for the multi-media support! We couldn't have delivered such high-quality video content without him. Thank you Ben!







Linux Foundation
============================
The Linux Foundation is the world’s leading home for collaboration on open source software, hardware, standards, and data. Linux Foundation projects are critical to the world’s infrastructure, including Linux, Kubernetes, Node.js, ONAP, PyTorch, RISC-V, SPDX, OpenChain, and more. The Linux Foundation focuses on leveraging best practices and addressing the needs of contributors, users, and solution providers to create sustainable models for open collaboration. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see its trademark usage page. Linux is a registered trademark of Linus Torvalds.






Linux Foundation Events
================================ https://events.linuxfoundation.org/

Over 85,000 open source technologists and leaders worldwide gather at Linux Foundation events annually to share ideas, learn and collaborate. Linux Foundation events are the meeting place of choice for open source maintainers, developers, architects, infrastructure managers, and sysadmins and technologists leading open source program offices, and other critical leadership functions.

These events are the best place to gain visibility within the open source community quickly and advance open source development work by forming connections with the people evaluating and creating the next generation of technology. They provide a forum to share and gain knowledge, help organizations identify software trends early to inform future technology investments, connect employers with talent, and showcase technologies and services to influential open source professionals, media, and analysts around the globe.

To learn more about the Linux Foundation events and to register, click here.






Linux Foundation Education
================================
https://training.linuxfoundation.org/?_gl=1%2A1a0zr5m%2A_gcl_au%2ANjU4OTY3MjE0LjE3MzA3MDI4ODY.%2A_ga%2AODkxMTgyNjEwLjE3MjI4MjQ3Nzc.%2A_ga_EMX7DDZMX4%2AMTczNDUxNjAyNS45LjEuMTczNDUxODI0MC42MC4wLjA.


The Linux Foundation Education Group works with expert instructors and experienced open source developers to create training courses for every level of experience, from complete newbies to veteran developers, as well as certification exams which demonstrate your skills to potential employers in a trusted verifiable way.

To get more information about specific courses and certification exams offered by the Linux Foundation, including technical requirements and other logistics, visit the Linux Foundation Education website.









https://www.youtube.com/watch?v=jwG5sXJzC-c




























********************************************************************
********************************************************************
02. The Model Application Relationship and the Power 
of Reproducibility

********************************************************************
********************************************************************




Chapter Overview
================================

Welcome! This course will prepare you for an exciting new role within the data world, whether that be a data scientist, machine learning engineer, or any other machine learning operations (MLOPs) role. The first path to success as a part of a machine learning-oriented team is understanding the landscape of machine learning development and deployment challenges. Still, since that topic is complex, we will take it one step at a time.





Learning Objectives
================================

By the end of this chapter, you should be able to:

Discuss the importance of reproducibility and replicability.
Explain the value behind applications' containerization in the context of replicability, reproducibility, and model deployment.
Discuss the model and application relationship.
Define the term “features” in the context of ML/AI.


Model or Application?
================================


Models and applications both work together to drive better business outcomes. New data professionals often have questions about how models and applications are related. Do we need applications if we have models? Do models replace the role of developers? This section will answer those questions by exploring how applications and models work together.









What is a Model?
================================


A model takes data as a request and responds with a prediction based on learned patterns. Just like your brain tries to connect something it observes within the context of your life, the model takes in data and processes it to predict using its training experience. One typical example is a recommendation engine. A recommendation engine is a model that learns from your choices, like the movies you watch, to predict and suggest new ones you might like. It's like a friend who knows your tastes and recommends films based on what you've enjoyed. This engine constantly improves its suggestions by learning from your viewing history. In a recommendation model, the data includes user interaction data, such as items viewed, purchased, or rated; user demographic information; item attributes, like genre, author, and release date for movies or books; and sometimes contextual information, like the time of day or location. The prediction output contains items the user will likely be interested in. This prediction is based on analyzing the data to understand user preferences and behavior patterns and applying them to a distribution. In a movie recommendation system, the prediction could be the movies the user will likely enjoy watching based on their past viewing history and preferences.




7 Types of Statistical Distributions
with Practical Examples

https://datasciencedojo.com/blog/types-of-statistical-distributions-in-ml/













Unpacking Predictions
================================


We have seen some need to clarify the term prediction when learning about machine learning predictions. A prediction is a formatted (often JSON, tensors, or arrays) response from the model to the application. The world of large language models like ChatGPT makes this even more confusing because the prediction can be a human-like text response rather than a simple numerical score or a class label typically expected from traditional models. In machine learning, a prediction is the output generated by a model after it has been trained on a dataset and then provided with new, unseen data. The nature of this output varies significantly depending on the model type and the specific task. For example, the prediction could be a category or label in a classification task, whereas in a regression task, it would be a continuous value.


https://www.ml-science.com/array








Types of Models
================================

A recommendation engine is only one type of model. The input data format and the output prediction depend on the model and use case. Some models, like recommendation engines, often use a mix of techniques.


            Model Examples
            
            Expand Regression Models
            Expand Classification Models
            Expand Clustering Models
            Expand Time Series Models
            Expand Dimensionality Reduction Models
            Expand Neural Networks


        Regression Models
        For predicting continuous values, like sales forecasting or determining price trends.
        
        
        
        
        
        Close Classification Models
        Aimed at categorizing data into predefined classes, such as spam detection in emails or image recognition.
        
        
        
        
        
        Close Clustering Models
        These models identify inherent groupings in data, which are helpful in market segmentation or organizing large data sets.
        
        
        
        
        
        
        
        
        
        Close Time Series Models
        Specialized in analyzing time-ordered data to forecast future points in the series, like stock prices or weather predictions.
        
        
        
        
        
        
        
        Close Dimensionality Reduction Models
        Used to simplify data, reduce its complexity, and retain essential features, often used in data visualization.
        
        
        
        
        
        
        
        Close Neural Networks
        Inspired by the human brain, these models can learn complex patterns through layers of interconnected nodes, pivotal in deep learning applications like language translation or autonomous vehicles.
        
        
        





Are Models the Full Story?
================================


The model is only part of the story regarding building intelligent applications. The model acts as the brain for our application. The application uses the model's response to determine logical flow, much like a human uses their brain to analyze a situation before using their body to execute their brain's determined actions. The application's logic is implemented based on the context of the model's outputs. The model application relationship is something that people new to the ML/AI world often find surprising. This surprise derives from their experience with the traditional software flow, where a developer finds patterns and uses data and code to drive an outcome. Data science teams take data and the determined outcome, then write code to build an algorithms-powered model. Instead of a developer hardcoding the desired inputs and outputs, the model learns patterns based on the data. The model also tests itself on how well it learned a concept and improved its known patterns during the training process—much like many of us do when studying for an exam or certification. We will go deeper into the model development lifecycle in future chapters.









Our Sample Application
================================


Pretend for a second that we are making an application whose job is to determine if a picture is or is not a duck and then sort the duck images into a “book of ducks.” Suppose you just went on a trip with your duck-loving friend and took 3000 pictures of waterfowl. You want to surprise your friend with a book of photographs containing all the ducks you encountered on your trip. However, you do not want to ruin the surprise by having your friend identify and sort the pictures. You also want to ensure this model works for others identifying ducks and potentially growing the duck-finding community! How might we go about this?









Duck Detection Application Attempt
================================


How would we start building our duck detection application without machine learning? The traditional software engineer might start by writing several loops and functions, attempting to find all the characteristics (or features) that identify a duck.

The code might look like the following:

// Pseudocode for Duck-or-Not-Duck Image Recognition
// Define the main function
function isItADuck(image):
    // Step 1: Check if the image is in the correct format
    if not isValidImageFormat(image):
    return "Error: Invalid image format. Please upload a JPG or PNG."

    // Step 2: Analyze the color spectrum of the image
    predominantColors = analyzePredominantColors(image)
    if "yellow" not in predominantColors:
    return "Probably not a duck. Ducks are often yellow."

    // Step 3: Look for the shape of a beak
    if not detectShape(image, "beak"):
    return "Probably not a duck. No beak detected."

    // Step 4: Check for presence of webbed feet
    if not detectShape(image, "webbed feet"):
    return "Might be a duck, but can't confirm without seeing webbed feet."

    // Step 5: Analyze the image for quacking sounds (just being silly)
    if detectSound(image, "quack"):
    return "Definitely a duck. It quacks!"

    // Step 6: Use advanced duck detection logic (very pseudo)
    if advancedDuckDetectionAlgorithm(image):
    return "Based on advanced analysis, this is indeed a duck."
    // If all else fails
    return "Uncertain if this is a duck. Please consult your duck watcher friend.".

A duck detection model may seem like a silly example, but let’s consider it for a moment. The pseudo application contained a loop that ended with consult your duck watcher friend, included some complex shape detection, and implemented advancedDuckDetectionAlgorithms. That code would be tricky to support. Identifying all possible images with and without ducks would be even more challenging. Imagine all the positions, environments, and quality of duck photos. An expert may also need to be consulted to identify many pictures, which can become complicated and expensive, defeating the application's purpose.








A Duck Image Detection Model
================================


What if we train a model to be an automated version of your duck watcher friend? We would need a model that our application asks, “Is this a duck?” much like sifting through all the pictures with a duck expert while asking similar questions. How would we train a duck detection model?

We still need a duck expert for the first step, which is to prepare the dataset. Machine learning teams spend much time finding and curating data; this project is no exception! We must first manually label images of ducks as duck or not_duck. This manual labeling step is called human in the loop. Initially, humans have to intervene in processes like image detection.

Humans create the labels themselves. The model is only as good as the data and the human’s ability to develop valuable labels. Adjusting the data to improve the model is a data-centric approach to AI. Tuning the model to work better with the data is called a model-centric approach to AI. 

Human-in-the-Loop Machine Learning by Robert (Munro) Monarch is an excellent resource if you want to learn more.

https://www.manning.com/books/human-in-the-loop-machine-learning

https://www.cse.wustl.edu/~jain/cse591-18/ftp/ml_human.pdf












Pseudocode for Duck or Not_Duck Detection Using Machine Learning
================================


Continuing with our example, let's assume we have consulted an expert and have some labeled duck data that we trust. Now, let's look at some pseudocode for a duck-or-not-duck detection model that uses our duck data:

// Step 1: Prepare the labeled dataset
labeledData = loadDataset("duck_images_dataset.csv")
// Example dataset format: [image_path, label]
// label is either "duck" or "not_duck"

// Step 2: Preprocess the data
preprocessedData = preprocessData(labeledData)
// Preprocessing steps include resizing images, normalizing pixel values, etc.

// Step 3: Split the dataset into training and testing sets trainSet, testSet = splitDataset(preprocessedData, trainSize=0.8)

// Step 4: Initialize the machine learning model
// For simplicity, let's assume we're using a convolutional neural network (CNN) suitable for image classification
model = initializeCNNModel()

// Step 5: Train the model on the training set
trainModel(model, trainSet)

// Step 6: Evaluate the model on the testing set to check its performance
evaluationResults = evaluateModel(model, testSet)
print("Model accuracy on test set:", evaluationResults.accuracy)

// Step 7: Use the trained model to predict new images
function predictDuck(image):
    preprocessedImage = preprocessImage(image)
    prediction = model.predict(preprocessedImage)
    if prediction == "duck":
        return "This is a duck."
    else:
        return "This is not a duck."






A Smarter Duck Detector
================================


We are making progress! We have a model that can predict whether or not the image is or is not a duck. We are now ready to sort some pictures. Or are we?

The model can determine if the image is or is not a duck, but then what? We still need to create a book of duck photographs with the pictures. This step requires an application. The application will use the model to get an is_duck or not_duck response like any other function call, but can then use that value to do something with the duck image. Here is an example of a prediction response from our duck detection model:

{
  "prediction": "duck",
  "confidence": 0.95,
  "message": "This is a duck."
}

The prediction is the model's classification result, indicating that the image has been identified as a duck.

The confidence is a decimal value representing the model's confidence in its prediction, on a scale from 0 to 1, where 1 indicates absolute certainty. In this case, the model is 95% confident in its prediction.

The message provides a human-readable interpretation of the prediction, which directly corresponds to the outcome of the pseudo-code's conditional logic.








Pseudocode for an Application Calling a Duck Identification Model
===================================================================


Below is more pseudocode where our model puts the duck and not_duck images into a dictionary. We are using a dictionary for simplicity's sake, but the application will have the sorted pictures and can then build an online book or other output with those images.

// Step 1: Load the pre-trained duck identification model
model = loadModel("path/to/duck_identification_model")

// Step 2: Define the path for input images
inputImagePath = "path/to/input/images"

// Step 3: Process and predict each image in the input path
processImages(inputImagePath)

// Function to load the pre-trained model
function loadModel(modelPath):
    // Load and return the model from the specified path
    // This could involve deserializing the model file into a model object
      return model

// Function to process images in the specified path
function processImages(imagePath):
    // Retrieve a list of image files from the specified path
    imageFiles = getImageFiles(imagePath)

    // Loop through each image file
    for imageFile in imageFiles:
    // Load the image
    image = loadImage(imageFile)

    // Preprocess the image for the model
    preprocessedImage = preprocessImageForModel(image)

    // Predict if the image is a duck
    isDuck = predictDuck(preprocessedImage, model)

    // Initialize an empty dictionary to act as the fake "duck_book" object
    duck_book = {"duck": [], "not_duck": []}

    // Handle the prediction result
    if isDuck:
      print(imageFile + " is a duck.")
      duck_book["duck"].append(imageFile)
    else:
      print(imageFile + " is not a duck.")
      duck_book["not_duck"].append(imageFile)

And just like that, our duck detector can now sift through our images and create a book. You might be asking:

How does a model detect ducks if we didn’t explain to it what a ”duck” is?
Does our model look for specific feather patterns, colors, beak size, or plumage?
Do we teach models to detect a duck the same way we teach humans?






Deftly Dive into Duck Deep Learning
================================



We are about to go deeper (no pun intended) than we need to, but for those wondering how a deep learning model learns, this section will help build a foundational understanding.

The model identifies ducks in images, not by explicitly searching for specific features like a "green bill" or "webbed feet', but by analyzing more abstract patterns and characteristics through its layers. Like onions, deep learning networks contain layers. Each layer activates specific nodes at certain magnitudes to pass information onto the next layer. The first layer is called the input layer, and the final layer is the output layer. In a Convolutional Neural Network (CNN), the initial layers may begin by detecting simple edges and textures.

In contrast, deeper layers combine these initial findings into more complex patterns that are not immediately recognizable to humans. These features would appear increasingly strange to humans as the data progresses through the network. The model learns these features during training by adjusting its internal parameters to reduce prediction errors, effectively identifying what combinations of abstract patterns map to a duck. The loss function is reduced through backpropagation and gradient descent to find a global minimum. The network leverages the chain rule for those who went through the pains of calculus. The chain rule is good for something besides tedious problem sets and is the star of backpropagation. The unique feature representation allows the model to generalize from the training data and accurately identify ducks in new, unseen images, even if the specific appearance varies widely from the examples it was trained on. We won’t need to go much deeper than that for this course. When using Kubeflow, we will have the power to use frameworks to build deep learning networks and kick-off training jobs. Here is a great video titled, "What is a Neural Network" that can help you digest this information if you are unfamiliar with deep learning or want to learn more. Again, do not worry if you don’t fully understand deep learning. It won’t impact your ability to succeed in this course.





Convolutional Neural Network (CNN) : https://en.wikipedia.org/wiki/Convolutional_neural_network



 loss function: https://developers.google.com/machine-learning/crash-course/linear-regression/loss

backpropagation and gradient descent  : https://developers.google.com/machine-learning/crash-course/linear-regression/loss


 chain rule : https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/a/chain-rule-review


"What is a Neural Network: https://www.youtube.com/watch?v=aircAruvnKk






The Application Summarized
================================


While our example was a vast oversimplification, think of the model as the brain and the application as the body, taking actions based on the brain's outputted predictions from the data it receives. The success of your application results from a delicate balance between the application and the model. The model could be embedded in the application lifecycle or operate as a model as a service, where it is deployed as a cloud endpoint.

Managing both the model lifecycle and application lifecycle can be complex, especially as we look to minimize technical debt. Technical debt is one of the consequences of prioritizing quick, immediate solutions in coding over more thorough, sustainable approaches. It involves a balance between solving problems fast and avoiding the creation of future issues due to hastily written code. Ignoring technical debt can lead to increased costs and complications. As the system evolves, integrating new features with old code becomes more difficult and expensive, similar to how unpaid loans accumulate interest over time. If you want to learn about machine learning technical debt, check out this Google research paper: "Machine Learning: The High Interest Credit Card of Technical Debt".



"Machine Learning: The High Interest Credit Card of Technical Debt".
https://research.google/pubs/machine-learning-the-high-interest-credit-card-of-technical-debt/



https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43146.pdf





Machine Learning Features and Feature Stores
==================================================





================================





================================







********************************************************************
********************************************************************
xx
********************************************************************
********************************************************************

================================




================================




================================




================================




================================




